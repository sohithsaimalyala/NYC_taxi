{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc080774-f41a-4503-a064-c0ac819eeb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reg fetch new batch of features and compute predictions and save to feature store\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4bd038bf-8550-420b-9ec2-308198fca80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46b8ae0d-58dd-4772-8931-25ff5fccb749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26612685-265e-4415-a149-5751be8f994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 12:23:51,990 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-03-04 12:23:52,026 INFO: Initializing external client\n",
      "2025-03-04 12:23:52,028 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-04 12:23:52,655 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1215673\n",
      "Fetching data from 2025-02-02 16:23:51.990130+00:00 to 2025-03-04 16:23:51.990130+00:00\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (13.20s) \n",
      "\n",
      "Processed 251 locations with sufficient data\n",
      "Error: cannot import name 'transform_ts_data_info_features' from 'src.data_utils' (d:\\EAS-500\\sp25_taxi-main\\src\\data_utils.py)\n",
      "\n",
      "Debug Info:\n",
      "Processed data shape: (171935, 3)\n",
      "Locations processed: 251\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>predicted_demand</th>\n",
       "      <th>pickup_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pickup_location_id  predicted_demand               pickup_hour\n",
       "0                    79             162.0 2025-03-04 18:00:00+00:00\n",
       "1                    87              29.0 2025-03-04 18:00:00+00:00\n",
       "2                    70               7.0 2025-03-04 18:00:00+00:00\n",
       "3                   143              54.0 2025-03-04 18:00:00+00:00\n",
       "4                    96               0.0 2025-03-04 18:00:00+00:00\n",
       "..                  ...               ...                       ...\n",
       "246                 253               0.0 2025-03-04 18:00:00+00:00\n",
       "247                  83               0.0 2025-03-04 18:00:00+00:00\n",
       "248                 207               0.0 2025-03-04 18:00:00+00:00\n",
       "249                  35               1.0 2025-03-04 18:00:00+00:00\n",
       "250                 259               1.0 2025-03-04 18:00:00+00:00\n",
       "\n",
       "[251 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.inference import get_feature_store, load_model_from_registry, get_model_predictions\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import src.config as config\n",
    "import lightgbm as lgb\n",
    "\n",
    "try:\n",
    "    # Step 1: Setup and get feature store data\n",
    "    current_date = pd.Timestamp.now(tz='Etc/UTC')\n",
    "    feature_store = get_feature_store()\n",
    "    \n",
    "    fetch_data_to = current_date - timedelta(hours=1)\n",
    "    fetch_data_from = fetch_data_to - timedelta(days=30)\n",
    "    \n",
    "    print(f\"Fetching data from {fetch_data_from} to {fetch_data_to}\")\n",
    "    \n",
    "    feature_view = feature_store.get_feature_view(\n",
    "        name=config.FEATURE_VIEW_NAME,\n",
    "        version=config.FEATURE_VIEW_VERSION\n",
    "    )\n",
    "    \n",
    "    # Get and prepare initial data\n",
    "    ts_data = feature_view.get_batch_data(\n",
    "        start_time=fetch_data_from,\n",
    "        end_time=fetch_data_to\n",
    "    )\n",
    "    \n",
    "    # Step 2: Prepare continuous time series data\n",
    "    ts_data['pickup_hour'] = ts_data['pickup_hour'].dt.tz_localize(None)\n",
    "    \n",
    "    # Create full date range\n",
    "    date_range = pd.date_range(\n",
    "        start=ts_data.pickup_hour.min(),\n",
    "        end=ts_data.pickup_hour.max(),\n",
    "        freq='H'\n",
    "    )\n",
    "    \n",
    "    # Process each location to ensure continuous data\n",
    "    processed_locations = []\n",
    "    \n",
    "    for location_id in ts_data.pickup_location_id.unique():\n",
    "        loc_data = ts_data[ts_data.pickup_location_id == location_id].copy()\n",
    "        \n",
    "        # Create continuous series for location\n",
    "        location_series = pd.DataFrame({\n",
    "            'pickup_hour': date_range,\n",
    "            'pickup_location_id': location_id\n",
    "        })\n",
    "        \n",
    "        # Merge with actual data\n",
    "        location_series = location_series.merge(\n",
    "            loc_data[['pickup_hour', 'rides']], \n",
    "            on='pickup_hour', \n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Fill missing values with 0\n",
    "        location_series['rides'] = location_series['rides'].fillna(0)\n",
    "        \n",
    "        # Only keep locations with sufficient data\n",
    "        if len(location_series) >= 672:  # 28 days * 24 hours\n",
    "            processed_locations.append(location_series)\n",
    "    \n",
    "    # Combine processed locations\n",
    "    if not processed_locations:\n",
    "        raise ValueError(\"No locations with sufficient data found\")\n",
    "    \n",
    "    ts_data_processed = pd.concat(processed_locations)\n",
    "    print(f\"\\nProcessed {len(processed_locations)} locations with sufficient data\")\n",
    "    \n",
    "    # Step 3: Generate features\n",
    "    from src.data_utils import transform_ts_data_info_features\n",
    "    features, _ = transform_ts_data_info_features(\n",
    "        ts_data,\n",
    "        window_size=504,  # 21 days\n",
    "        step_size=24\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Add missing column\n",
    "    features['rides_t-672'] = 0\n",
    "    \n",
    "    # Step 4: Load and prepare model\n",
    "    model = load_model_from_registry()\n",
    "    if isinstance(model, lgb.Booster):\n",
    "        model.params['predict_disable_shape_check'] = True\n",
    "    elif hasattr(model, 'steps') and isinstance(model.steps[-1][1], lgb.LGBMRegressor):\n",
    "        model.steps[-1][1].set_params(predict_disable_shape_check=True)\n",
    "    \n",
    "    # Step 5: Generate predictions\n",
    "    predictions = get_model_predictions(model, features)\n",
    "    \n",
    "    if predictions is not None and not predictions.empty:\n",
    "        predictions['pickup_hour'] = current_date.ceil('h')\n",
    "        \n",
    "        # Save to feature store\n",
    "        feature_group = feature_store.get_or_create_feature_group(\n",
    "            name=config.FEATURE_GROUP_MODEL_PREDICTION,\n",
    "            version=1,\n",
    "            description=\"Predictions from LGBM Model\",\n",
    "            primary_key=['pickup_location_id', 'pickup_hour'],\n",
    "            event_time='pickup_hour',\n",
    "        )\n",
    "        \n",
    "        feature_group.insert(predictions, write_options={\"wait_for_job\": False})\n",
    "        \n",
    "        print(f\"\\nSaved {len(predictions)} predictions to feature store\")\n",
    "        print(\"\\nTop 10 locations by predicted demand:\")\n",
    "        print(predictions.sort_values('predicted_demand', ascending=False)[\n",
    "            ['pickup_location_id', 'predicted_demand']\n",
    "        ].head(10))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(\"\\nDebug Info:\")\n",
    "    if 'ts_data_processed' in locals():\n",
    "        print(f\"Processed data shape: {ts_data_processed.shape}\")\n",
    "        print(f\"Locations processed: {ts_data_processed.pickup_location_id.nunique()}\")\n",
    "    \n",
    "predictions if 'predictions' in locals() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22253dce-140a-4296-a48b-35c6c7655b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 12:24:15,605 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-03-04 12:24:15,628 INFO: Initializing external client\n",
      "2025-03-04 12:24:15,631 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-04 12:24:16,255 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1215673\n",
      "Downloading model artifact (0 dirs, 1 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "from src.inference import load_model_from_registry\n",
    "\n",
    "model = load_model_from_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b868f801-03a3-4d51-8e24-88231e664f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from 2025-02-02 16:24:19.231284+00:00 to 2025-03-04 16:24:19.231284+00:00\n",
      "2025-03-04 12:24:19,231 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-03-04 12:24:19,241 INFO: Initializing external client\n",
      "2025-03-04 12:24:19,241 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-04 12:24:19,831 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1215673\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (9.99s) \n",
      "Data loaded: 171935 records\n",
      "Error: name 'transform_ts_data_info_features' is not defined\n",
      "\n",
      "Debug Info:\n",
      "Features shape: (251, 675)\n",
      "Number of time lag columns: 672\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>predicted_demand</th>\n",
       "      <th>pickup_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pickup_location_id  predicted_demand               pickup_hour\n",
       "0                    79             162.0 2025-03-04 18:00:00+00:00\n",
       "1                    87              29.0 2025-03-04 18:00:00+00:00\n",
       "2                    70               7.0 2025-03-04 18:00:00+00:00\n",
       "3                   143              54.0 2025-03-04 18:00:00+00:00\n",
       "4                    96               0.0 2025-03-04 18:00:00+00:00\n",
       "..                  ...               ...                       ...\n",
       "246                 253               0.0 2025-03-04 18:00:00+00:00\n",
       "247                  83               0.0 2025-03-04 18:00:00+00:00\n",
       "248                 207               0.0 2025-03-04 18:00:00+00:00\n",
       "249                  35               1.0 2025-03-04 18:00:00+00:00\n",
       "250                 259               1.0 2025-03-04 18:00:00+00:00\n",
       "\n",
       "[251 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.inference import get_feature_store, load_model_from_registry, get_model_predictions\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import src.config as config\n",
    "import lightgbm as lgb\n",
    "\n",
    "try:\n",
    "    # Step 1: Setup time window\n",
    "    current_date = pd.Timestamp.now(tz='Etc/UTC')\n",
    "    fetch_data_to = current_date - timedelta(hours=1)\n",
    "    fetch_data_from = fetch_data_to - timedelta(days=30)\n",
    "    \n",
    "    print(f\"Fetching data from {fetch_data_from} to {fetch_data_to}\")\n",
    "    \n",
    "    # Step 2: Get feature store data\n",
    "    feature_store = get_feature_store()\n",
    "    feature_view = feature_store.get_feature_view(\n",
    "        name=config.FEATURE_VIEW_NAME,\n",
    "        version=config.FEATURE_VIEW_VERSION\n",
    "    )\n",
    "    \n",
    "    ts_data = feature_view.get_batch_data(\n",
    "        start_time=fetch_data_from,\n",
    "        end_time=fetch_data_to\n",
    "    )\n",
    "    \n",
    "    ts_data['pickup_hour'] = ts_data['pickup_hour'].dt.tz_localize(None)\n",
    "    ts_data = ts_data.sort_values(['pickup_location_id', 'pickup_hour'])\n",
    "    \n",
    "    print(f\"Data loaded: {len(ts_data)} records\")\n",
    "    \n",
    "    # Step 3: Generate initial features\n",
    "    from src.data_utils import transform_ts_data_info_features_and_target  # or _loop if needed\n",
    "    features = transform_ts_data_info_features(\n",
    "        ts_data,\n",
    "        window_size=504,  # 21 days\n",
    "        step_size=24\n",
    "    )\n",
    "    \n",
    "    # Step 4: Add all required time lag columns\n",
    "    max_lag = 672  # Maximum required lag\n",
    "    current_lags = set(col for col in features.columns if col.startswith('rides_t-'))\n",
    "    \n",
    "    # Add missing time lag columns with zeros\n",
    "    for lag in range(1, max_lag + 1):\n",
    "        col_name = f'rides_t-{lag}'\n",
    "        if col_name not in current_lags:\n",
    "            features[col_name] = 0\n",
    "    \n",
    "    # Step 5: Load and prepare model\n",
    "    model = load_model_from_registry()\n",
    "    \n",
    "    # Modify model parameters to handle shape mismatch\n",
    "    if isinstance(model, lgb.Booster):\n",
    "        model.params['predict_disable_shape_check'] = True\n",
    "    elif hasattr(model, 'steps') and isinstance(model.steps[-1][1], lgb.LGBMRegressor):\n",
    "        model.steps[-1][1].set_params(predict_disable_shape_check=True)\n",
    "    \n",
    "    # Step 6: Generate predictions\n",
    "    predictions = get_model_predictions(model, features)\n",
    "    \n",
    "    if predictions is not None and not predictions.empty:\n",
    "        # Add timestamp and save predictions\n",
    "        predictions['pickup_hour'] = current_date.ceil('h')\n",
    "        \n",
    "        feature_group = feature_store.get_or_create_feature_group(\n",
    "            name=config.FEATURE_GROUP_MODEL_PREDICTION,\n",
    "            version=1,\n",
    "            description=\"Predictions from LGBM Model\",\n",
    "            primary_key=['pickup_location_id', 'pickup_hour'],\n",
    "            event_time='pickup_hour',\n",
    "        )\n",
    "        \n",
    "        feature_group.insert(predictions, write_options={\"wait_for_job\": False})\n",
    "        \n",
    "        print(f\"\\nSaved {len(predictions)} predictions to feature store\")\n",
    "        print(\"\\nTop 10 locations by predicted demand:\")\n",
    "        print(predictions.sort_values('predicted_demand', ascending=False)[\n",
    "            ['pickup_location_id', 'predicted_demand']\n",
    "        ].head(10))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(\"\\nDebug Info:\")\n",
    "    if 'features' in locals():\n",
    "        print(f\"Features shape: {features.shape}\")\n",
    "        print(f\"Number of time lag columns: {len([c for c in features.columns if c.startswith('rides_t-')])}\")\n",
    "    \n",
    "# Display predictions\n",
    "predictions if 'predictions' in locals() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "751d63ab-8e98-4087-a3cf-d79bd1bd88e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>predicted_demand</th>\n",
       "      <th>pickup_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-03-04 18:00:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>251 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pickup_location_id  predicted_demand               pickup_hour\n",
       "0                    79             162.0 2025-03-04 18:00:00+00:00\n",
       "1                    87              29.0 2025-03-04 18:00:00+00:00\n",
       "2                    70               7.0 2025-03-04 18:00:00+00:00\n",
       "3                   143              54.0 2025-03-04 18:00:00+00:00\n",
       "4                    96               0.0 2025-03-04 18:00:00+00:00\n",
       "..                  ...               ...                       ...\n",
       "246                 253               0.0 2025-03-04 18:00:00+00:00\n",
       "247                  83               0.0 2025-03-04 18:00:00+00:00\n",
       "248                 207               0.0 2025-03-04 18:00:00+00:00\n",
       "249                  35               1.0 2025-03-04 18:00:00+00:00\n",
       "250                 259               1.0 2025-03-04 18:00:00+00:00\n",
       "\n",
       "[251 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[\"pickup_hour\"] = current_date.ceil('h')\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b171dd4-628a-4c46-af00-92cee476f090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-04 12:24:37,334 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-03-04 12:24:37,349 INFO: Initializing external client\n",
      "2025-03-04 12:24:37,351 INFO: Base URL: https://c.app.hopsworks.ai:443\n",
      "2025-03-04 12:24:37,870 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1215673\n"
     ]
    }
   ],
   "source": [
    "from src.inference import get_feature_store\n",
    "\n",
    "feature_group = get_feature_store().get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_MODEL_PREDICTION,\n",
    "    version=1,\n",
    "    description=\"Predictions from LGBM Model\",\n",
    "    primary_key=[\"pickup_location_id\", \"pickup_hour\"],\n",
    "    event_time=\"pickup_hour\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ba8f0db-022e-4f8a-ac34-6fd8bb095b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Rows 251/251 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: taxi_hourly_model_prediction_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1215673/jobs/named/taxi_hourly_model_prediction_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('taxi_hourly_model_prediction_1_offline_fg_materialization', 'SPARK'),\n",
       " None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_group.insert(predictions, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6108be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "con_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
